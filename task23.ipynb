{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Deep Neural Networks (DNNs)\n",
    "Deep Neural Networks (DNNs) are a class of machine learning algorithms that are built on the concept of artificial neural networks (ANNs). They consist of multiple layers of interconnected neurons, where each layer transforms the input data in a way that allows the network to learn complex patterns and representations.\n",
    "\n",
    "# Convolutional Neural Networks (CNNs)\n",
    " Convolutional Neural Networks (CNNs) are a specialized type of DNN designed specifically for processing structured grid data, such as images. CNNs are particularly effective for image recognition and classification tasks. The key idea behind CNNs is to automatically and adaptively learn spatial hierarchies of features from input images.\n",
    "\n",
    "## How CNNs Work\n",
    "CNNs typically consist of the following layers:\n",
    "\n",
    "## Convolutional Layer:\n",
    "\n",
    "Purpose: The convolutional layer is the core building block of a CNN. It performs a convolution operation on the input data using a set of filters (or kernels) to produce feature maps. These feature maps capture the spatial features of the input, such as edges, textures, and patterns.\n",
    "Operation: The filter slides over the input image, computing the dot product between the filter and a local region of the input image. This results in a smaller, transformed version of the input called the feature map.\n",
    "Example: If the input is a 32x32x3 image (width, height, channels), and you apply a 3x3 filter with a stride of 1, the output will be a 30x30x1 feature map.\n",
    "Activation Function (ReLU):\n",
    "\n",
    "Purpose: The Rectified Linear Unit (ReLU) is commonly used as the activation function in CNNs. It introduces non-linearity into the network, allowing the model to learn more complex patterns.\n",
    "Operation: ReLU simply replaces all negative pixel values in the feature map with zero, while keeping the positive values unchanged.\n",
    "Pooling Layer:\n",
    "\n",
    "Purpose: The pooling layer is used to reduce the spatial dimensions (width and height) of the feature maps, thereby reducing the number of parameters and computational cost. It also helps in making the network invariant to small translations of the input.\n",
    "Types: The most common type is max pooling, which selects the maximum value from each region of the feature map.\n",
    "Example: Applying a 2x2 max pooling with a stride of 2 on a 30x30 feature map will reduce it to a 15x15 feature map.\n",
    "Fully Connected (Dense) Layer:\n",
    "\n",
    "Purpose: The fully connected layer connects every neuron in one layer to every neuron in another layer. It is typically used at the end of the network to classify the input into different categories.\n",
    "Operation: The feature maps are flattened into a vector, and then passed through the dense layers to produce the final output.\n",
    "Output Layer:\n",
    "\n",
    "Purpose: The output layer is where the final classification or prediction is made. The number of neurons in this layer corresponds to the number of classes in the classification problem.\n",
    "Activation Function: For multi-class classification, the softmax activation function is commonly used, which outputs probabilities for each class.\n",
    "CNN Architectures\n",
    "Several popular CNN architectures have been developed over the years, each with its unique structure and advantages.\n",
    "\n",
    "## 1. VGG (Visual Geometry Group)\n",
    "VGG-16 and VGG-19: These are deep CNN architectures with 16 and 19 layers, respectively. VGG networks are known for their simplicity and use of small 3x3 filters throughout the entire network.\n",
    "Architecture: The network is structured in a sequence of convolutional layers, each followed by a ReLU activation function and max pooling. After several convolutional layers, the network ends with fully connected layers and a softmax output.\n",
    "Key Idea: VGG demonstrates that the depth of the network is critical for improving performance, provided the architecture has small, manageable filters.\n",
    "## 2. Xception\n",
    "Architecture: Xception is an extension of the Inception architecture, where the Inception modules have been replaced with depthwise separable convolutions. This drastically reduces the number of parameters while maintaining or improving performance.\n",
    "Key Features: Xception uses depthwise separable convolutions, which perform a spatial convolution followed by a pointwise convolution. This separates the learning of spatial and channel features, making the network more efficient.\n",
    "Object Detection\n",
    "Object detection involves not only classifying objects in an image but also localizing them with bounding boxes. Popular object detection algorithms include:\n",
    "\n",
    "## R-CNN (Region-Based Convolutional Neural Networks):\n",
    "Process: R-CNN generates region proposals and then classifies each proposal using a CNN. It also refines the bounding box coordinates.\n",
    "YOLO (You Only Look Once):\n",
    "Process: YOLO divides the image into a grid and directly predicts bounding boxes and class probabilities for each grid cell. This makes YOLO extremely fast and suitable for real-time detection.\n",
    "Deep Learning with Keras in Python\n",
    "Keras is a high-level neural networks API that runs on top of TensorFlow. It is user-friendly, modular, and easy to extend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Initialize the CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Add Convolutional Layer\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
    "\n",
    "# Add Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Add another Convolutional Layer\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add Fully Connected Layer\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# Add Output Layer\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
