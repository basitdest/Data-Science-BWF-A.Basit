{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Neural Networks and Deep Learning Concepts with Implementations\n",
                "\n",
                "## 1. The Perceptron\n",
                "- **Perceptron** is the simplest form of a neural network, used for binary classification tasks.\n",
                "- It consists of **input features**, **weights**, **bias**, and an **activation function**.\n",
                "- The perceptron makes a decision by summing the weighted inputs and applying a step function.\n",
                "\n",
                "### Implementation: Simple Perceptron Example\n",
                "```python\n",
                "from sklearn.datasets import load_iris\n",
                "from sklearn.linear_model import Perceptron\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Load dataset and prepare\n",
                "iris = load_iris()\n",
                "X = iris.data[:, (2, 3)]  # petal length and width\n",
                "y = (iris.target == 0).astype(int)  # classify Setosa as 1\n",
                "\n",
                "# Train-test split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Train Perceptron\n",
                "per_clf = Perceptron()\n",
                "per_clf.fit(X_train, y_train)\n",
                "\n",
                "# Predictions\n",
                "y_pred = per_clf.predict(X_test)\n",
                "\n",
                "# Accuracy\n",
                "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "```\n",
                "\n",
                "## 2. Multi-Layer Perceptron (MLP) and Backpropagation\n",
                "- An **MLP** extends the perceptron by adding hidden layers between input and output layers.\n",
                "- Each neuron in a layer performs a weighted sum followed by a non-linear activation function.\n",
                "- **Backpropagation** adjusts the weights by calculating the gradient of the loss function with respect to each weight.\n",
                "\n",
                "### Implementation: Simple MLP for MNIST\n",
                "```python\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "\n",
                "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
                "X_train = X_train.reshape((X_train.shape[0], 28*28)).astype(\"float32\") / 255\n",
                "X_test = X_test.reshape((X_test.shape[0], 28*28)).astype(\"float32\") / 255\n",
                "\n",
                "mlp_model = keras.Sequential([\n",
                "    layers.Dense(300, activation=\"relu\", input_shape=(28*28,)),\n",
                "    layers.Dense(100, activation=\"relu\"),\n",
                "    layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "\n",
                "mlp_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
                "mlp_model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
                "```\n",
                "\n",
                "## 3. Regression MLPs\n",
                "- MLPs can also be used for regression tasks where the output is continuous rather than categorical.\n",
                "- The final layer typically uses a linear activation function to output a single continuous value.\n",
                "\n",
                "### Implementation: MLP for Regression\n",
                "```python\n",
                "from sklearn.datasets import fetch_california_housing\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "housing = fetch_california_housing()\n",
                "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
                "scaler = StandardScaler()\n",
                "X_train = scaler.fit_transform(X_train_full)\n",
                "X_test = scaler.transform(X_test)\n",
                "\n",
                "regression_mlp = keras.Sequential([\n",
                "    layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
                "    layers.Dense(1)\n",
                "])\n",
                "\n",
                "regression_mlp.compile(loss=\"mse\", optimizer=\"sgd\")\n",
                "history = regression_mlp.fit(X_train, y_train_full, epochs=20, validation_split=0.2)\n",
                "```\n",
                "\n",
                "## 4. Implementing MLPs with Keras\n",
                "- **Keras** provides a high-level API for building neural networks.\n",
                "- MLPs are easily implemented using the Sequential API where layers are stacked sequentially.\n",
                "\n",
                "### Implementation: Simple MLP with Keras\n",
                "```python\n",
                "# Already covered in MLP example above\n",
                "```\n",
                "\n",
                "## 5. Installing TensorFlow 2\n",
                "- TensorFlow 2 can be installed using pip. It includes GPU support and various deep learning tools.\n",
                "- Use the command `pip install tensorflow` to install.\n",
                "\n",
                "```bash\n",
                "!pip install tensorflow\n",
                "```\n",
                "\n",
                "## 6. Building an Image Classifier Using the Sequential API\n",
                "- The Sequential API allows for building neural networks layer by layer.\n",
                "- Ideal for simple feedforward models like CNNs for image classification.\n",
                "\n",
                "### Implementation: CNN for CIFAR-10\n",
                "```python\n",
                "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
                "\n",
                "cnn_model = keras.Sequential([\n",
                "    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
                "    layers.MaxPooling2D((2, 2)),\n",
                "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
                "    layers.MaxPooling2D((2, 2)),\n",
                "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
                "    layers.Flatten(),\n",
                "    layers.Dense(64, activation=\"relu\"),\n",
                "    layers.Dense(10, activation=\"softmax\")\n",
                "])\n",
                "\n",
                "cnn_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
                "cnn_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
                "```\n",
                "\n",
                "## 7. Building a Regression MLP Using the Sequential API\n",
                "- Similar to the classification example, but for continuous outputs.\n",
                "\n",
                "### Implementation: Regression MLP (already covered in Regression MLP section)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}